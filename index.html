<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Abhijit Kundu</title>
    <meta name="author" content="Abhijit Kundu" />
    <meta name="description" content="Personal homepage of Abhijit Kundu.
" />
    <meta name="keywords" content="computer-vision, robotics, machine-learning, 3D-vision, academic-website" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="Abhijit Kundu" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Abhijit Kundu | about" />
    <meta property="og:url" content="https://abhijitkundu.info/" />
    <meta property="og:description" content="Personal homepage of Abhijit Kundu.
" />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="about" />
    <meta name="twitter:description" content="Personal homepage of Abhijit Kundu.
" />
    
    <meta name="twitter:site" content="@_abhijit_kundu_" />
    <meta name="twitter:creator" content="@_abhijit_kundu_" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://abhijitkundu.info/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Social Icons -->
          <div class="navbar-brand social">
            <a href="mailto:%65%6D%61%69%6C@%61%62%68%69%6A%69%74%6B%75%6E%64%75.%69%6E%66%6F" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=GGcjtCsAAAAJ&amp;h" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://twitter.com/_abhijit_kundu_" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            
          </div>
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">Abhijit</span>  Kundu
          </h1>
          <p class="desc"></p>
        </header>

        <article>
          <div class="profile float-right">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/prof_pic.jpg" alt="prof_pic.jpg">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <p>Passionate about advancing the frontiers of computer vision, machine learning, and robotics.</p>

<p>I currently work at <a href="https://deepmind.google/" target="_blank" rel="noopener noreferrer">Google DeepMind</a>. Previously I was with the <a href="https://research.google/teams/perception/" target="_blank" rel="noopener noreferrer">Perception</a> team at <a href="https://research.google/" target="_blank" rel="noopener noreferrer">Google Research</a>.</p>

<p>I finished my PhD in <a href="https://www.cc.gatech.edu/degree-programs/phd-computer-science" target="_blank" rel="noopener noreferrer">Computer Science</a> from <a href="https://www.gatech.edu/" target="_blank" rel="noopener noreferrer">Georgia Tech</a>. At Georgia Tech, I was co-advised by <a href="https://rehg.org/" target="_blank" rel="noopener noreferrer">Jim Rehg</a> and <a href="https://dellaert.github.io/" target="_blank" rel="noopener noreferrer">Frank Dellaert</a>. Before that, I was at <a href="https://robotics.iiit.ac.in/" target="_blank" rel="noopener noreferrer">Robotics Research Lab</a> of <a href="https://www.iiit.ac.in/" target="_blank" rel="noopener noreferrer">IIIT Hyderabad</a>, India where I worked with <a href="https://www.iiit.ac.in/people/faculty/mkrishna/" target="_blank" rel="noopener noreferrer">Prof. K Madhava Krishna</a> and <a href="https://faculty.iiit.ac.in/~jawahar/" target="_blank" rel="noopener noreferrer">Prof. C. V Jawahar</a>.</p>

          </div>

          <!-- News -->          
          <div class="news">
            <h2>news</h2>
            <div class="table-responsive">
              <table class="table table-sm table-borderless"> 
                <tr>
                  <th scope="row">Jul 11, 2024</th>
                  <td>
                    <img class="emoji" title=":book:" alt=":book:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png" height="20" width="20"> We released <a href="https://omninocs.github.io/" target="_blank" rel="noopener noreferrer">OmniNOCS</a> a new large unified NOCS dataset. To appear at <a href="https://eccv.ecva.net/Conferences/2024" target="_blank" rel="noopener noreferrer">ECCV 2024</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 1, 2024</th>
                  <td>
                    <img class="emoji" title=":book:" alt=":book:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png" height="20" width="20"> Two new papers: <a href="https://m-niemeyer.github.io/nerfmeshing/" target="_blank" rel="noopener noreferrer">NeRFMeshing</a> to appear at <a href="https://3dvconf.github.io/2024/" target="_blank" rel="noopener noreferrer">3DV 2024</a> and <a href="https://nileshkulkarni.github.io/nifty/" target="_blank" rel="noopener noreferrer">NIFTY</a> to appear at <a href="https://cvpr.thecvf.com/Conferences/2024" target="_blank" rel="noopener noreferrer">CVPR 2024</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Dec 1, 2023</th>
                  <td>
                    <img class="emoji" title=":earth_americas:" alt=":earth_americas:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f30e.png" height="20" width="20"> Google Maps now has <a href="https://blog.google/products/maps/google-maps-october-2023-update/" target="_blank" rel="noopener noreferrer">immersive views for routes</a>. See how they work via this <a href="https://blog.google/products/maps/google-maps-immersive-view-routes/" target="_blank" rel="noopener noreferrer">blog post</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 1, 2022</th>
                  <td>
                    <img class="emoji" title=":book:" alt=":book:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png" height="20" width="20"> Two papers <a href="projects/pnf">Panoptic Neural Fields</a> and <a href="https://github.com/google-research/kubric" target="_blank" rel="noopener noreferrer">Kubric</a> accepted at <a href="https://cvpr2022.thecvf.com/" target="_blank" rel="noopener noreferrer">CVPR 2022</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 29, 2021</th>
                  <td>
                    <img class="emoji" title=":earth_americas:" alt=":earth_americas:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f30e.png" height="20" width="20"> Some of our <a href="https://blog.google/products/maps/google-maps-101-ai-power-new-features-io-2021/" target="_blank" rel="noopener noreferrer">work</a> with Google Maps were <a href="https://blog.google/products/maps/five-maps-updates-io-2021/" target="_blank" rel="noopener noreferrer">announced</a> at Google I/O.
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Selected papers -->
          <div class="publications">
            <h2>selected <a href="publications/">publications</a>
</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <!-- Create website_entry  -->
        

        <!-- Create teaser_entry  -->
        


        <!-- Entry teaser -->
        <div class="col-sm-3"><a href="/projects/pnf"><img class="img-fluid rounded" src="/assets/img/pnf/kitti360_nvs50_train02.webp"></a></div>

        <!-- Entry bib key -->
        <div id="KunduCVPR2022PNF" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation</div>
          <!-- Author -->
          <div class="author">
                  <a href=""><b>Abhijit Kundu</b></a>,Â <a href="https://www.kylegenova.com/" target="_blank" rel="noopener noreferrer">Kyle Genova</a>,Â <a href="https://scholar.google.com/citations?user=2eADYP8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Xiaoqi Yin</a>,Â <a href="https://www.alirezafathi.org/" target="_blank" rel="noopener noreferrer">Alireza Fathi</a>,Â <a href="https://www.linkedin.com/in/carolinepantofaru/" target="_blank" rel="noopener noreferrer">Caroline Pantofaru</a>,Â <a href="https://geometry.stanford.edu/member/guibas/" target="_blank" rel="noopener noreferrer">Leonidas Guibas</a>,Â <a href="https://taiya.github.io/" target="_blank" rel="noopener noreferrer">Andrea Tagliasacchi</a>,Â <a href="https://dellaert.github.io/" target="_blank" rel="noopener noreferrer">Frank Dellaert</a>,Â <a href="https://www.cs.princeton.edu/~funk/" target="_blank" rel="noopener noreferrer">Thomas Funkhouser.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In CVPR</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2205.04334" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv <i class="ai ai-arxiv ai-1x"></i></a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/pdf/2205.04334.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF <i class="fas fa-file-pdf"></i></a>
            <a href="/projects/pnf" class="btn btn-sm z-depth-0" role="button">Website <i class="fas fa-home"></i></a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present Panoptic Neural Fields (PNF), an object-aware neural scene representation that decomposes a scene into a set of objects (things) and background (stuff).  Each object is represented by an oriented 3D bounding box and a multi-layer perceptron (MLP) that takes position, direction, and time and outputs density and radiance.  The background stuff is represented by a similar MLP that additionally outputs semantic labels. Each object MLPs are instance-specific and thus can be smaller and faster than previous object-aware approaches, while still leveraging category-specific priors incorporated via meta-learned initialization. Our model builds a panoptic radiance field representation of any scene from just color images. We use off-the-shelf algorithms to predict camera poses, object tracks, and 2D image semantic segmentations. Then we jointly optimize the MLP weights and bounding box parameters using analysis-by-synthesis with self-supervision from color images and pseudo-supervision from predicted semantic segmentations. During experiments with real-world dynamic scenes, we find that our model can be used effectively for several tasks like novel view synthesis, 2D panoptic segmentation, 3D scene editing, and multiview depth prediction.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KunduCVPR2022PNF</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kundu, Abhijit and Genova, Kyle and Yin, Xiaoqi and Fathi, Alireza and Pantofaru, Caroline and Guibas, Leonidas and Tagliasacchi, Andrea and Dellaert, Frank and Funkhouser, Thomas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <!-- Create website_entry  -->
        

        <!-- Create teaser_entry  -->
        


        <!-- Entry teaser -->
        <div class="col-sm-3"><a href="/projects/multiview_segmentation"><img class="img-fluid rounded" src="/assets/img/multiview_segmentation/virtualMVFusion_thumbnail.gif"></a></div>

        <!-- Entry bib key -->
        <div id="KunduECCV2020VirtualMVFusion" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Virtual Multi-view Fusion for 3D Semantic Segmentation</div>
          <!-- Author -->
          <div class="author">
                  <a href=""><b>Abhijit Kundu</b></a>,Â <a href="https://scholar.google.com/citations?user=2eADYP8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Xiaoqi Yin</a>,Â <a href="https://www.alirezafathi.org/" target="_blank" rel="noopener noreferrer">Alireza Fathi</a>,Â <a href="http://www.cs.toronto.edu/~dross/" target="_blank" rel="noopener noreferrer">David Ross</a>,Â Brian Brewington,Â <a href="https://www.cs.princeton.edu/~funk/" target="_blank" rel="noopener noreferrer">Thomas Funkhouser</a>,Â <a href="https://www.linkedin.com/in/carolinepantofaru/" target="_blank" rel="noopener noreferrer">Caroline Pantofaru.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In ECCV</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2007.13138" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv <i class="ai ai-arxiv ai-1x"></i></a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/pdf/2007.13138.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF <i class="fas fa-file-pdf"></i></a>
            <a href="/projects/multiview_segmentation" class="btn btn-sm z-depth-0" role="button">Website <i class="fas fa-home"></i></a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Semantic segmentation of 3D meshes is an important problem for 3D scene understanding. In this paper we revisit the classic multiview representation of 3D meshes and study several techniques that make them effective for 3D semantic segmentation of meshes. Given a 3D mesh reconstructed from RGBD sensors, our method effectively chooses different virtual views of the 3D mesh and renders multiple 2D channels for training an effective 2D semantic segmentation model. Features from multiple per view predictions are finally fused on 3D mesh vertices to predict mesh semantic segmentation labels. Using the large scale indoor 3D semantic segmentation benchmark of ScanNet, we show that our virtual views enable more effective training of 2D semantic segmentation networks than previous multiview approaches. When the 2D per pixel predictions are aggregated on 3D surfaces, our virtual multiview fusion method is able to achieve significantly better 3D semantic segmentation results compared to all prior multiview approaches and recent 3D convolution approaches.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KunduECCV2020VirtualMVFusion</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Virtual Multi-view Fusion for 3D Semantic Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kundu, Abhijit and Yin, Xiaoqi and Fathi, Alireza and Ross, David and Brewington, Brian and Funkhouser, Thomas and Pantofaru, Caroline}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ECCV}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-58586-0_31}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-030-58586-0_31}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-58586-0}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <!-- Create website_entry  -->
        

        <!-- Create teaser_entry  -->
        


        <!-- Entry teaser -->
        <div class="col-sm-3"><a href="/projects/3D-RCNN"><img class="img-fluid rounded" src="/assets/img/3drcnn/3drcnn_thumbnail.jpg"></a></div>

        <!-- Entry bib key -->
        <div id="3DRCNN_CVPR2018" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">3D-RCNN: Instance-level 3D Object Reconstruction via Render-and-Compare</div>
          <!-- Author -->
          <div class="author">
                  <a href=""><b>Abhijit Kundu</b></a>,Â <a href="https://www.biostat.wisc.edu/~yli/" target="_blank" rel="noopener noreferrer">Yin Li</a>,Â <a href="https://rehg.org" target="_blank" rel="noopener noreferrer">James M. Rehg.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In CVPR</em> 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/3DRCNN_CVPR18.pdf" class="btn btn-sm z-depth-0" role="button">PDF <i class="fas fa-file-pdf"></i></a>
            <a href="/projects/3D-RCNN" class="btn btn-sm z-depth-0" role="button">Website <i class="fas fa-home"></i></a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present a fast inverse-graphics framework for instance-level 3D scene understanding. We train a deep convolutional network that learns to map image regions to the full 3D shape and pose of all object instances in the image. Our method produces a compact 3D representation of the scene, which can be readily used for applications like autonomous driving. Many traditional 2D vision outputs, like instance segmentations and depth-maps, can be obtained by simply rendering our output 3D scene model. We exploit class-specific shape priors by learning a low dimensional shape-space from collections of CAD models. We present novel representations of shape and pose, that strive towards better 3D equivariance and generalization. In order to exploit rich supervisory signals in the form of 2D annotations like segmentation, we propose a differentiable Render-and-Compare loss that allows 3D shape and pose to be learned with 2D supervision. We evaluate our method on the challenging real-world datasets of Pascal3D+ and KITTI, where we achieve state-of-the-art results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">3DRCNN_CVPR2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kundu, Abhijit and Li, Yin and Rehg, James M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{3D-RCNN: Instance-level 3D Object Reconstruction via Render-and-Compare}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CVPR.2018.00375}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/CVPR.2018.00375}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <!-- Create website_entry  -->
        

        <!-- Create teaser_entry  -->
        


        <!-- Entry teaser -->
        <div class="col-sm-3"><a href="/projects/fso"><img class="img-fluid rounded" src="/assets/img/fso/fso_thumbnail.jpg"></a></div>

        <!-- Entry bib key -->
        <div id="KunduCVPR2016VideoFSO" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Feature Space Optimization for Semantic Video Segmentation</div>
          <!-- Author -->
          <div class="author">
                  <a href=""><b>Abhijit Kundu</b></a>,Â <a href="https://vibhav-vineet.github.io/" target="_blank" rel="noopener noreferrer">Vibhav Vineet</a>,Â <a href="https://vladlen.info/" target="_blank" rel="noopener noreferrer">Vladlen Koltun.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In CVPR</em> 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/VideoFSO_CVPR16.pdf" class="btn btn-sm z-depth-0" role="button">PDF <i class="fas fa-file-pdf"></i></a>
            <a href="https://bitbucket.org/infinitei/videoparsing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code <i class="fab fa-github"></i></a>
            <a href="/assets/pdf/VideoFSO_CVPR16_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides <i class="fas fa-file-powerpoint"></i></a>
            <a href="/projects/fso" class="btn btn-sm z-depth-0" role="button">Website <i class="fas fa-home"></i></a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present an approach to long-range spatio-temporal regularization in semantic video segmentation. Temporal regularization in video is challenging because both the camera and the scene may be in motion. Thus Euclidean distance in the space-time volume is not a good proxy for correspondence. We optimize the mapping of pixels to a Euclidean feature space so as to minimize distances between corresponding points. Structured prediction is performed by a dense CRF that operates on the optimized features. Experimental results demonstrate that the presented approach increases the accuracy and temporal consistency of semantic video segmentation.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KunduCVPR2016VideoFSO</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Feature Space Optimization for Semantic Video Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kundu, Abhijit and Vineet, Vibhav and Koltun, Vladlen}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CVPR.2016.345}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/CVPR.2016.345}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <!-- Create website_entry  -->
        

        <!-- Create teaser_entry  -->
        


        <!-- Entry teaser -->
        <div class="col-sm-3"><a href="/projects/JointSegRec"><img class="img-fluid rounded" src="/assets/img/JointSegRec/JointSegRec_thumbnail.jpg"></a></div>

        <!-- Entry bib key -->
        <div id="KunduECCV2014JointSegRec" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Joint Semantic Segmentation and 3D Reconstruction from Monocular Video</div>
          <!-- Author -->
          <div class="author">
                  <a href=""><b>Abhijit Kundu</b></a>,Â <a href="https://www.biostat.wisc.edu/~yli/" target="_blank" rel="noopener noreferrer">Yin Li</a>,Â <a href="https://dellaert.github.io/" target="_blank" rel="noopener noreferrer">Frank Dellaert</a>,Â <a href="https://web.engr.oregonstate.edu/~lif/" target="_blank" rel="noopener noreferrer">Fuxin Li</a>,Â <a href="https://rehg.org" target="_blank" rel="noopener noreferrer">James M. Rehg.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In ECCV</em> 2014
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/HybridSFM-ECCV2014.pdf" class="btn btn-sm z-depth-0" role="button">PDF <i class="fas fa-file-pdf"></i></a>
            <a href="/assets/pdf/HybridSFM-ECCV2014-supp.pdf" class="btn btn-sm z-depth-0" role="button">Supp <i class="fas fa-file-pdf"></i></a>
            <a href="/projects/JointSegRec" class="btn btn-sm z-depth-0" role="button">Website <i class="fas fa-home"></i></a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present an approach for joint inference of 3D scene structure and semantic labeling for monocular video. Starting with monocular image stream, our framework produces a 3D volumetric semantic + occupancy map, which is much more useful than a series of 2D semantic label images or a sparse point cloud produced by traditional semantic segmentation and Structure from Motion(SfM) pipelines respectively. We derive a Conditional Random Field (CRF) model defined in the 3D space, that jointly infers the semantic category and occupancy for each voxel. Such a joint inference in the 3D CRF paves the way for more informed priors and constraints, which is otherwise not possible if solved separately in their traditional frameworks. We make use of class specific semantic cues that constrain the 3D structure in areas, where multiview constraints are weak. Our model comprises of higher order factors, which helps when the depth is unobservable.We also make use of class specific semantic cues to reduce either the degree of such higher order factors, or to approximately model them with unaries if possible. We demonstrate improved 3D structure and temporally consistent semantic segmentation for difficult, large scale, forward moving monocular image sequences.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KunduECCV2014JointSegRec</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Joint Semantic Segmentation and 3D Reconstruction from Monocular Video}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kundu, Abhijit and Li, Yin and Dellaert, Frank and Li, Fuxin and Rehg, James M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ECCV}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-10599-4_45}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-10599-4_45}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-319-10599-4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%65%6D%61%69%6C@%61%62%68%69%6A%69%74%6B%75%6E%64%75.%69%6E%66%6F" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=GGcjtCsAAAAJ&amp;h" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://twitter.com/_abhijit_kundu_" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            
            </div>

            <div class="contact-note">
              
            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container text-center">
        Â© Copyright 2024 Abhijit Kundu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-4839252-4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-4839252-4');
  </script>
  </body>
</html>

